{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology/chatgpt 251\n",
      "us-news/donaldtrump 329\n",
      "technology/elon-musk 245\n",
      "world/lgbt-rights 339\n",
      "world/israel-hamas-war 401\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Edge()\n",
    "\n",
    "# keywords = ['ChatGPT', 'Donald%20Trump', 'Elon%20Musk', 'LGBT', 'Israel']\n",
    "keywords = ['technology/chatgpt', 'us-news/donaldtrump', 'technology/elon-musk', 'world/lgbt-rights', 'world/israel-hamas-war'] # The Gardian\n",
    "text_dict = {}\n",
    "\n",
    "for keyword in keywords:\n",
    "\n",
    "    # url = 'https://www.scmp.com/search/'+keyword # SCMP\n",
    "    # url = 'https://newssearch.chinadaily.com.cn/en/search?query='+keyword # China Daily\n",
    "    # url = 'https://www.thesun.co.uk/?s='+keyword # The Sun\n",
    "    # url = 'https://edition.cnn.com/search?q='+keyword # CNN\n",
    "    url = 'https://www.theguardian.com/'+keyword # The Gardian\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(8)\n",
    "    \n",
    "    # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\") # SCMP\n",
    "    # time.sleep(3) # SCMP\n",
    "\n",
    "    # articles = driver.find_elements(By.CSS_SELECTOR, 'a[class=\"ebqqd5k0 css-1r4kaks ef1hf1w0\"]') # SCMP\n",
    "    # articles = driver.find_elements(By.CSS_SELECTOR, 'h4>a') # China Daily\n",
    "    # articles = driver.find_elements(By.CSS_SELECTOR, 'a[class=\"text-anchor-wrap\"]') # The Sun\n",
    "    # articles = driver.find_elements(By.CSS_SELECTOR, 'span[class=\"container__headline-text\"]') # CNN\n",
    "    articles = driver.find_elements(By.CSS_SELECTOR, 'a[data-link-name=\"article\"]') # The Gardian\n",
    "    \n",
    "    article_links = [article.get_attribute('href') for article in articles] # SCMP, China Daily, The Sun, The Gardian\n",
    "    # article_links = [article.get_attribute('data-zjs-href') for article in articles] # CNN\n",
    "    \n",
    "    article_links = list(set(article_links)) # The Gardian\n",
    "\n",
    "    paragraphs = []\n",
    "\n",
    "    for article_link in article_links:\n",
    "\n",
    "        driver.get(article_link)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # sections = driver.find_elements(By.CSS_SELECTOR, 'section') # SCMP\n",
    "        # sections = driver.find_elements(By.CSS_SELECTOR, 'div[id=\"Content\"]') # China Daily\n",
    "        # sections = driver.find_elements(By.CSS_SELECTOR, 'div[class=\"article__content\"]') # The Sun, CNN\n",
    "        sections = driver.find_elements(By.CSS_SELECTOR, 'div[id=\"maincontent\"]') # The Gardian\n",
    "        \n",
    "        paragraphs += [section.text for section in sections]\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        if not paragraph:\n",
    "            continue\n",
    "        current_sentences = paragraph.split('\\n')\n",
    "        index = 0\n",
    "        while index < len(current_sentences):\n",
    "            if current_sentences[index].endswith('.'):\n",
    "                index += 1\n",
    "            elif current_sentences[index].endswith('?'):\n",
    "                index += 1\n",
    "            elif current_sentences[index].endswith('!'):\n",
    "                index += 1\n",
    "            elif current_sentences[index].endswith('\"'):\n",
    "                index += 1\n",
    "            elif current_sentences[index].endswith(\"'\"):\n",
    "                index += 1\n",
    "            else:\n",
    "                current_sentences.pop(index)\n",
    "        sentences += current_sentences\n",
    "\n",
    "    text_dict[keyword] = sentences\n",
    "\n",
    "    # with open(keyword+'_SCMP.txt', 'w', encoding='UTF-8') as f: # SCMP\n",
    "    # with open(keyword+'_ChinaDaily.txt', 'w', encoding='UTF-8') as f: # China Daily\n",
    "    # with open(keyword+'_TheSun.txt', 'w', encoding='UTF-8') as f: # The Sun\n",
    "    # with open(keyword+'_CNN.txt', 'w', encoding='UTF-8') as f: # CNN\n",
    "    with open(keyword.split('/')[1]+'_TheGradian.txt', 'w', encoding='UTF-8') as f: # The Gardian\n",
    "        f.write('\\n'.join(sentences))\n",
    "    print(keyword, len(sentences))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT_ChinaDaily.txt 144\n",
      "ChatGPT_CNN.txt 120\n",
      "ChatGPT_SCMP.txt 151\n",
      "ChatGPT_TheGradian.txt 251\n",
      "ChatGPT_TheSun.txt 254\n",
      "Donald%20Trump_ChinaDaily.txt 182\n",
      "Donald%20Trump_CNN.txt 63\n",
      "Donald%20Trump_SCMP.txt 98\n",
      "Donald%20Trump_TheGradian.txt 329\n",
      "Donald%20Trump_TheSun.txt 313\n",
      "Elon%20Musk_ChinaDaily.txt 157\n",
      "Elon%20Musk_CNN.txt 88\n",
      "Elon%20Musk_SCMP.txt 121\n",
      "Elon%20Musk_TheGradian.txt 245\n",
      "Elon%20Musk_TheSun.txt 309\n",
      "Israel_ChinaDaily.txt 103\n",
      "Israel_CNN.txt 100\n",
      "Israel_SCMP.txt 99\n",
      "Israel_TheGradian.txt 401\n",
      "Israel_TheSun.txt 287\n",
      "LGBT_ChinaDaily.txt 121\n",
      "LGBT_CNN.txt 140\n",
      "LGBT_SCMP.txt 238\n",
      "LGBT_TheGradian.txt 339\n",
      "LGBT_TheSun.txt 398\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "    with open(filename, 'r', encoding='UTF-8') as file:\n",
    "        print(filename, len(file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
