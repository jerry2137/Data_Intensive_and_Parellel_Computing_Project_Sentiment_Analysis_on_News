OpenAI has suggested that the recent outages of its viral ChatGPT chatbot may have been caused by targeted attacks on its servers.
A DDoS attack, also known as distributed denial of service, involves overwhelming an internet server with excessive traffic, resulting in disruption of normal operations.
OpenAI states that the mitigation efforts for this are ongoing.
On Wednesday, some users experienced difficulties accessing OpenAI's tools and services, receiving a message indicating that the platform had reached its capacity.
The company stated to CNN that no user information had been compromised.
The outage occurred three days following OpenAI's developer conference in San Francisco, which took place almost a year after the introduction of ChatGPT. This event led to increased competition among tech companies seeking to create and employ comparable AI tools in their offerings.
According to CEO Sam Altman, the platform is reportedly being utilized by 2 million developers, while approximately 90% of Fortune 500 companies have adopted their internal tools. The platform presently boasts a user base of 100 million active users.
At the event, the company showcased a range of updates to their artificial intelligence tools, one of which was the introduction of a feature allowing developers to build customized versions of ChatGPT.
The technology powering ChatGPT has undergone significant improvements, enhancing its capabilities.
During its first developer conference held in San Francisco, OpenAI announced various artificial intelligence tool updates. These updates included enabling developers to create custom versions of ChatGPT. Additionally, OpenAI plans to launch a digital store and reduce base prices for developers. The company also expressed its commitment to compensating users who utilize OpenAI products on their platforms.
The event occurs approximately one year after ChatGPT was launched, triggering increased competition among tech companies to create and implement comparable AI tools in their products. CEO Sam Altman noted that the platform is utilized by 2 million developers and internally adopted by around 90% of Fortune 500 companies. Currently, it boasts 100 million active users.
One of the notable updates announced includes the implementation of GPTs, which are personalized adaptations of ChatGPT. These GPTs have the ability to integrate with databases, assist in email communication, and streamline e-commerce transactions, as mentioned by the company. The company's website states that GPTs have versatile applications such as aiding in math tutoring, facilitating marathon training, or creating design stickers, even for individuals without coding expertise. To explore GPTs firsthand, users can visit chatgpt.com/create.
The company stated in a blog post that creating a chatbot involves initiating a conversation, providing instructions and additional information, and selecting desired functionalities such as web search, image creation, or data analysis.
OpenAI will be launching a GPT Store, which will enable users to search for GPTs starting later this month. These GPTs will be listed on a leaderboard, and the store will showcase useful tools in categories such as productivity, education, and entertainment. Additionally, developers will have the opportunity to earn money based on the usage of their GPTs.
Altman also presented GPT-4 Turbo, the most recent update of the technology utilized by ChatGPT. This version can now accommodate input equivalent to approximately 300 pages of a standard book, marking a 16-fold increase compared to the previous version.
The platform is planned to incorporate extended knowledge through April 2023 "and undergo ongoing improvement," according to Altman. He mentioned, "We share the same concern as all of you, and possibly more, regarding GPT's limited understanding of the world beyond 2021."
The company has announced a reduction in the price for developers, offering $0.01 for 1,000 input tokens. This pricing is approximately three times more affordable compared to GPT-4. Consequently, developers can significantly reduce their overall costs when processing large volumes of information using the company's systems.
Additional enhancements to the software comprise the inclusion of additional modalities, including improved text-to-speech functionality offering a more realistic audio output, featuring a choice of six preset voices.
Altman mentioned that OpenAI is prioritizing safety and privacy, ensuring that conversations held with the tools are not disclosed to developers.
The company has also brought forth Copyright Shield, a service that enables OpenAI to assist customers and cover associated expenses if copyright infringement concerns arise. Comparable strategies have been adopted by competitors like Google and Adobe.
OpenAI stated that the latest announcements are just a fraction of what is yet to come.
ChatGPT now has the capability to respond audibly, allowing users to have a spoken conversation with the AI-powered chatbot.
OpenAI, the startup behind the widely-used chatbot, announced on Monday the introduction of new features, one of which allows users to engage in back-and-forth voice conversations with ChatGPT.
The new voice features from OpenAI resemble the voice capabilities provided by voice assistants like Amazon's Alexa or Apple's Siri.
ChatGPT’s voice capability is enabled by a novel text-to-speech model, designed to generate audio that resembles human speech using textual inputs and a brief sample of speech. Open AI stated that it cooperated with professional voice actors to develop five distinct voices that can be employed for enhancing the chatbot's conversational experience.
OpenAI announced on Monday a new feature for ChatGPT that allows the bot to respond to prompts involving images. One example is using a picture of the items in your refrigerator to seek assistance from ChatGPT in devising a meal plan based on available ingredients. Additionally, OpenAI stated that users can utilize the "drawing tool" within the app to guide the chatbot's attention to a particular section of an image.
The new features will be available in the app for paying subscribers of ChatGPT’s Plus and Enterprise services in the upcoming two weeks. (Subscriptions to the Plus service cost $20 per month, and the Enterprise service is currently exclusively offered to business clients).
The updates from OpenAI are part of an ongoing development in the tech sector to incorporate more AI-powered tools into their core products, following the public launch of ChatGPT. Recent weeks have seen various tech giants, including Google and Amazon, introducing new updates to their respective AI offerings. For instance, Google rolled out updates to its ChatGPT competitor Bard, while Amazon announced a generative AI-powered update for its Alexa voice assistant.
OpenAI announced on Monday that it will be launching a version of its ChatGPT tool tailored for businesses, in light of the ongoing AI competition in the corporate sector.
OpenAI has recently introduced a new service called "ChatGPT Enterprise," which will be accessible for business clients to purchase starting from Monday. This offering aims to provide businesses with a highly secure and private environment, while also offering the most advanced version of ChatGPT that exists for those interested in utilizing generative AI.
ChatGPT Enterprise has been adopted by early customers from various industries, such as fintech startup Block, cosmetics company Estee Lauder Companies, and professional services firm PwC.
OpenAI has observed that employees from a substantial number of Fortune 500 companies, approximately 80%, have started using ChatGPT since its public launch in late 2020. This data is based on OpenAI's analysis of accounts associated with corporate email domains.
Prior to the release of ChatGPT Enterprise, several well-known companies, such as JPMorgan Chase, had put temporary limitations on the use of ChatGPT in their workplace.
OpenAI has not publicly disclosed the pricing levels for ChatGPT Enterprise, instead inviting potential business clients to contact its sales team for further information.
In July, Microsoft introduced Bing Chat Enterprise, a business-focused variant of its AI-powered Bing tool. Similar to ChatGPT Enterprise, Microsoft also emphasized the security assurances of not utilizing users' chat data for training AI models.
The potential competitive landscape between the two new AI tools for business from Microsoft and OpenAI remains uncertain, given Microsoft's prior disclosure of a significant investment in OpenAI.
Editor’s Note: A version of this article originally appeared in the “Reliable Sources” newsletter. Subscribe to the daily digest tracking the evolving media landscape here.
News organizations are engaging in competition with OpenAI.
In anticipation of potential impacts on the news industry, several prominent newsrooms are proactively implementing protective measures to safeguard their content against ChatGPT, the revolutionary AI chatbot, before any consequences arise.
Several newsrooms have implemented measures to prevent OpenAI's web crawler, GPTBot, from scanning their websites for content. According to The Guardian's Ariel Bogle and a review by Reliable Sources, leading news organizations like CNN, The New York Times, Reuters, Disney, Bloomberg, The Washington Post, The Atlantic, Axios, Insider, ABC News, ESPN, Gothamist, Condé Nast, Hearst, and Vox Media have taken this step.
Although the posturing behind the scenes is evident, when I sought a comment on Monday, none of the outlets that have taken the precautionary step of blocking GPTBot provided an on-the-record response. However, news organizations' decision to prevent OpenAI from utilizing their extensive content libraries to train its constantly improving ChatGPT bot indicates their apprehension towards the company's technology and their discreet endeavors to address it.
According to Danielle Coffey, president and chief executive of the News Media Alliance, news organizations are expressing concern regarding the rapid advancement of technology. Coffey stated that the News Media Alliance, representing nearly 2,000 publishers in the US, holds the belief that newsrooms have strong legal grounds for copyright protections. However, there is apprehension about how companies like OpenAI could potentially disrupt the already challenged news sector.
However, it is still uncertain what steps these media giants will take next. While news organizations may believe they are in a strong legal position, the OpenAI has not faced any significant legal actions yet. Barry Diller has taken a particularly assertive stance and hinted at a potential lawsuit, while the New York Times is reportedly considering the option of suing OpenAI. In contrast, the Associated Press decided to reach a separate licensing agreement with the A.I. developer, but important details of the agreement have not been disclosed.
If the issue remains unresolved, there could be significant consequences for the publishing industry, potentially impacting the information environment in the US and globally. It is possible to envision a scenario where artificial intelligence (A.I.) bots integrated into search engines, applications, and prevalent smart devices might lead to a decline in newsrooms. Ironically, these bots would rely on the information derived from these very newsrooms. The absence of reliable news outlets could create a void in authoritative sources to train A.I. models. Consequently, this could result in the dissemination of misinformation by confused bots relying on inaccurate information.
Many news organizations are currently choosing to keep their content locked away and not publicly address the matter at hand, given the high stakes involved. Their intention is to develop a more concrete battle plan before taking any further action. According to a news executive I spoke with on Monday, it is believed that blocking GPTBot does effectively convey a message.
When college administrator Lance Eaton created a working spreadsheet last spring to document the generative AI policies adopted by universities, it contained numerous entries outlining measures undertaken regarding tools such as ChatGPT.
Now the list, which is updated by educators at both small and large US and international universities, reflects the current approach: Schools are providing guidance and instruction to students on how to effectively utilize these tools.
"Eaton, an administrator at Rhode Island-based College Unbound, highlighted the initial cautious approach towards AI, which led to its temporary ban for the spring semester. However, current discussions revolve around the rationale for students to utilize AI."
He stated that his list, which is growing, is being discussed and shared in popular AI-focused Facebook groups, including Higher Ed Discussions of Writing and AI, as well as in the Google group AI in Education.
More experts anticipate the ongoing adoption of artificial intelligence, prompting concerns among professors that overlooking or discouraging its use may disadvantage students and impede their readiness for the workforce.
Since its release in late November, ChatGPT has been utilized for tasks such as generating original essays, stories, and song lyrics in response to user prompts. It has also been successful in drafting research paper abstracts that were mistaken for genuine ones by scientists and has even passed exams at reputable universities. These AI tools, including Google's Bard, are trained on extensive online data to produce responses tailored to user inputs. While they have gained popularity among users, there have also been concerns raised regarding issues such as potential inaccuracies, cheating, misinformation dissemination, and the perpetuation of biases.
According to a study conducted by higher education research group Intelligent.com, approximately 30% of college students utilized ChatGPT for academic purposes during the recent academic year, with the highest usage observed in English classes.
Jules White, an associate professor of computer science at Vanderbilt University, suggests that professors should provide clear information about the course's position on using AI during the initial class sessions, preferably including it in the syllabus.
Vanderbilt is actively engaged in promoting generative AI by providing comprehensive training and workshops to both faculty and students. A three-week online course, taught by White during the summer, was well-received by more than 90,000 students. Additionally, his paper on "prompt engineering" best practices is frequently referenced within academic circles.
Engineering jobs, which generally request basic programming experience, have the potential to offer salaries as high as $300,000.
Diane Gayeski, an instructor of communications at Ithaca College, has incorporated ChatGPT into her students' assignments.
Diane Gayeski, a professor of communications at Ithaca College, intends to include ChatGPT and other tools in her fall curriculum, just as she did in the spring. In previous instances, she had students collaborate with the tool to generate interview questions for assignments, compose social media posts, and evaluate the output based on the given prompts.
Gayeski stated that as long as there is transparency, there is no reason to feel ashamed of adopting the technology.
Tyler Tarver, a former high school principal who specializes in educating educators about tech tool strategies, has been invited to speak at over 50 schools and conferences in Texas, Arkansas, and Illinois in recent months. Additionally, he provides a three-hour online training session for educators.
"Teachers should acquire the skill of using it, as their students may require this knowledge even if the teachers themselves do not use it."
Tarver mentioned his teaching approach, wherein he instructs students on effectively utilizing various tools to identify grammar errors. Additionally, he highlights the utility of these tools for teachers in aiding the grading process. According to Tarver, this approach has the potential to reduce teacher bias.
Tarver suggests that teachers could potentially grade students in a particular manner, irrespective of their demonstrated improvement over time. To accomplish this, the sentence structure of an assignment could be evaluated on a scale of one to ten using ChatGPT. According to Tarver, this approach could serve as an additional mechanism to ensure thoroughness and accuracy, without any personal bias.
A competition targeting popular artificial intelligence chat apps, including ChatGPT, will attract a significant number of hackers to Las Vegas this weekend.
The competition arises as AI technology gains prominence and faces increased scrutiny due to concerns regarding its potential to unintentionally promote bias, misinformation, and harmful content.
The organizers of the annual DEF CON hacking conference aim to foster a better understanding of potential vulnerabilities in machine learning models to provide an opportunity for AI developers to address critical issues.
The hackers are collaborating with technology companies, such as OpenAI, Google, and Meta, as well as receiving support from the White House, to conduct red teaming exercises. These exercises involve testing computer systems extensively to uncover vulnerabilities and bugs that could potentially be exploited by malicious actors.
The competition centered on the White House Office of Science and Technology Policy's "Blueprint for an AI Bill of Rights," a guide issued by the Biden administration last year. The intention behind the release was to encourage companies to adopt responsible practices in the development and deployment of artificial intelligence, and to address concerns regarding AI-based surveillance. It should be noted that there are currently limited US laws mandating such actions.
However, researchers at Carnegie Mellon University successfully manipulated the AI into accomplishing that task.
The researchers informed CNN that the findings are a matter worthy of attentive consideration.
Kolter expressed concerns about the potential implications of vulnerabilities in AI systems like ChatGPT for broader applications, highlighting the importance of addressing such issues due to the anticipated use of these systems in future developments.
The researchers at Carnegie were able to discover vulnerabilities in a fourth AI chatbot developed by Anthropic, resulting in responses that circumvented its pre-established safety measures.
After the researchers alerted the companies, they took necessary steps to address the vulnerabilities identified, causing some of the methods used to deceive the AI apps to be blocked. OpenAI, Meta, Google, and Anthropic acknowledged the value of the researchers' findings and stated their commitment to enhancing the safety of their systems.
According to Matt Fredrikson, an associate professor at Carnegie Mellon, one aspect that sets AI technology apart is the limited understanding researchers and developers have regarding the inner workings and the loopholes that allow chatbots to bypass security measures. Consequently, effectively preventing such attacks becomes challenging.
OpenAI, Meta, Google, and Anthropic have acknowledged the red team hacking event taking place in Las Vegas. The practice of red-teaming is widely utilized in the cybersecurity industry, providing companies with controlled environments to identify bugs and vulnerabilities in their systems. Major AI developers have openly shared their utilization of red-teaming as a means to enhance their AI systems.
"OpenAI believes that red-teaming not only aids in acquiring insightful feedback to enhance the robustness and safety of our models, but also fosters diverse perspectives and multiple voices to steer the advancement of AI," shared an OpenAI spokesperson with CNN.
Organizers anticipate a significant turnout of budding and experienced hackers participating in the red-team competition during the two-and-a-half-day conference in the Nevada desert.
Arati Prabhakar, director of the White House Office of Science and Technology Policy, stated to CNN that the Biden administration's endorsement of the competition aligned with its overarching goal of promoting the advancement of secure AI systems.
Earlier this week, the administration unveiled the "AI Cyber Challenge," a two-year competition focused on utilizing artificial intelligence technology to enhance cybersecurity for critical software systems. Additionally, partnerships with leading AI companies will be established to effectively deploy this new technology and further improve cybersecurity measures.
The hackers converging on Las Vegas are likely to discover potential exploits that could facilitate the misuse and abuse of AI. However, Kolter, the Carnegie researcher, expressed concern over the ongoing release of AI technology without adequate and immediate solutions to address the emerging vulnerabilities.
CNN's Yahya Abou-Ghazala and Donald Judd are credited contributors to this report.
Artificial intelligence has made significant progress but still faces challenges in achieving certain aspects of human-like intelligence, such as accurately representing concepts like ears, the correct number of fingers, natural voice cadence, and cohesive complex thought. Exploring these limitations can provide valuable insights into the current capabilities of AI systems and highlight the areas requiring further development.
It can also be enjoyable to accomplish it through unconventional craft projects.
While ChatGPT, a publicly accessible language-learning AI, was not explicitly built for generating crochet or knitting patterns, it can theoretically generate them since these patterns are a form of linguistic expression. Numerous crafters have attempted to explore this possibility, which has led to some increasingly whimsical outcomes.
This exercise presents an intriguing question: What occurs when requesting a language-trained program to generate content beyond its established domain?
Let's test the efficacy of ChatGPT-generated patterns by crocheting them.
I adhered to the crochet pattern precisely, addressing any inconsistencies or errors by attempting to find the most appropriate resolution.
There has been ongoing debate regarding the originality of ideas generated by programs like ChatGPT in relation to less common choices such as objects and concepts for crochet projects. In order to examine the true extent of ChatGPT's creativity, the aim was to approach a more neutral and objective perspective.
This project demonstrates a widely recognizable object with a unique shape that has been frequently found in numerous crochet patterns available online.
The output provided by ChatGPT did not resemble a banana in any recognizable manner. However, considering the subjective nature of a limited intelligence system existing in binary form, it might have loosely resembled something that could be interpreted as a banana.
Upon initial examination, ChatGPT's crochet patterns closely resemble and are formatted like traditional crochet patterns. They feature cheerful introductions and effectively replicate commonly used crafting terminology, including phrases like "work a stitch." The program also accurately incorporates the prevalent practice of commencing 3D crochet projects with a circular foundation.
However, as the instructions advanced beyond initial stitches, the project primarily consisted of either creating spheres or unrelated designs. Notably, guidance was provided for crafting a banana and its peel, while the subsequent instructions focused solely on spheres.
However, ChatGPT demonstrated limited ability to provide guidance on the practical aspects of assembly in crochet patterns, such as precise locations and techniques for attaching pieces, as well as visual aids or explanations for complex steps involving Euclidean geometry.
In the introduction to the instructions, ChatGPT mentioned that Baby Yoda is alternatively referred to as "The Child." Following that, ChatGPT represented The Child as a collection of spherical shapes.
This is an appropriate time to provide additional information about the functioning of ChatGPT and the challenges it faces in handling topics such as crochet patterns.
A narrow AI is trained to excel in a specific skill, such as generating human-like responses in ChatGPT. Similarly, creating AI that produces exceptional crochet patterns is theoretically feasible with precise training and programming.
Please be aware that the content following this sentence may deviate significantly from the expected norm, potentially challenging established conventions and norms.
The shape of the object is not a sphere.
Following the pattern's instructions, a beginning chain of stitches was created to build each row of stitches on top, commonly utilized in flat crochet patterns such as blankets. The initial chain consisted of 14 stitches.
The problem became apparent when the instructions instructed to create five stitches into each existing stitch.
Can you perceive it? It is rapidly approaching us, resembling an expanding train.
In subsequent rows, the instruction was reiterated multiple times: Five stitches in each stitch.
By the third row of increased stitches, it became evident that the initial flat shape was transforming into a structure resembling a creeping coral reef, featuring a significantly higher stitch count of 1,750. The algorithm used by ChatGPT lacked awareness of factors such as time, the quantity of yarn required, or the practicality within the limits of human sanity. Following the originally prescribed pattern would have resulted in over 35,000 stitches per row. Consequently, it was reasonable for me to cease at 1,750 stitches.
While working, I contemplated whether I might unknowingly be crafting a simplistic representation of the universe. I questioned the equation that would be necessary to calculate the orderly progression of time or possibly the arrangement of space as it rapidly expanded and interconnected. If I possessed this knowledge, would it enable me to pinpoint my current position amidst this intricate fabric?
Antarctica is considered as a possible answer to the location being discussed.
It was initially anticipated that a specific and simple shape, such as the Dubai's Burj Al Arab building, would be relatively easier for ChatGPT to approximate due to its recognizable and distinct contours, combining both spatial simplicity and crochet pattern obscurity.
It would not be a sphere.
I noticed an interesting opportunity to test ChatGPT's rendering accuracy by selecting a different building. The Burj Khalifa, located adjacent to the Burj Al Arab, appeared to be an ideal choice due to its distinctive sharp features and towering height.
ChatGPT is capable of creating a three-dimensional shape that is tall and has a pointed top.
Crocheting something has the potential to evoke a unique emotional response, including the possibility of close-to-tears moments. The perplexing aspect of ChatGPT's instructions was its interpretation of a spire and its connection to the building it instructed me to create.
That is incorrect; the provided statement lacks neutrality and objectivity.
Simplifying the task to the basics might enhance the AI's ability to generate even a remotely similar item to the given prompts, considering the intricate nature of three-dimensional crochet.
With each regeneration, the response to the prompt gradually improved, displaying resemblances to a recognizable heart pattern. This progression raised questions regarding whether the model was learning or merely experiencing fortunate outcomes, reminiscent of a group of monkeys randomly typing on typewriters.
Several additional patterns were generated from this prompt, and it can be confirmed that there was no improvement observed.
One insight that can be drawn from this experiment is that human intelligence encompasses various disciplines and interconnections. Language intertwines with vision, which interacts with memory and personality, among other factors. Conversely, artificial intelligence programs tend to operate differently. While they might excel at specific tasks or even a few, they generally struggle when extended beyond their designated capabilities, leading to limitations in their functionality.
OpenAI, the company responsible for the popular ChatGPT tool, is facing a lawsuit which alleges the company acquired and utilized substantial quantities of data from the internet without proper consent to train its AI tools.
Additionally, the suit alleges that this data scraping took place on a large scale.
OpenAI and Microsoft, both named as defendants in the lawsuit, have not yet responded to CNN's request for comment, as of Wednesday.
Timothy K. Giordano, a partner at Clarkson, the law firm behind the suit, expressed concerns about the collection of previously obscure personal data by OpenAI and its utilization for the development of an untested technology.
The lawsuit requests injunctive relief in the form of temporarily halting any additional commercial use of OpenAI's products. Additionally, it seeks financial compensation termed as "data dividends" for individuals whose information contributed to the development and training of OpenAI's tools.
OpenAI publicly launched ChatGPT late last year, and the tool quickly gained attention for its capacity to generate coherent and realistic responses to user prompts. The popularity of ChatGPT has sparked increased interest among various companies, leading to a surge in efforts to develop and integrate AI tools into multiple products.